{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoI ML CNN Experiment\n",
    "\n",
    "- Train op fashion mnist\n",
    "- Laat experimenten zien: kies 2 - 3 params, kies een range en voer tests uit. Doel is 93% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 11:26:34.594537: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 11:26:39.218988: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-01 11:26:39.223398: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-01 11:26:39.223443: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from src.data import make_dataset\n",
    "from src.models import imagemodels\n",
    "from src.models import train_model\n",
    "import gin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedConfigFileIncludesAndImports(filename='cnn.gin', imports=[], includes=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load config for this notebook\n",
    "gin.parse_config_file(\"cnn.gin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MNIST data\n",
    "train_dataloader, test_dataloader = make_dataset.get_MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set some other parameters\n",
    "import torch.optim as optim\n",
    "from src.models import metrics\n",
    "optimizer = optim.Adam\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "accuracy = metrics.Accuracy()\n",
    "from src.models import train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voer een experiment uit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuratie voor het experiment\n",
    "\n",
    "Sla de gewenste structuur voor de lagen op in een lijst configuraties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class NNLayerConfig:\n",
    "    \"\"\"Class for storing config and results for a layer.\"\"\"\n",
    "    loss: float\n",
    "    num_params: int\n",
    "    filter1_size: int\n",
    "    filter1_stride: int\n",
    "    filter1_padding: int\n",
    "    filter2_size: int\n",
    "    filter2_stride: int\n",
    "    filter2_padding: int\n",
    "    dim_1: int\n",
    "    dim_2: int\n",
    "\n",
    "    # TODO calculate input and output dims\n",
    "    def calc_dim_1():\n",
    "        return 0\n",
    "    def calc_dim_2():\n",
    "        return 0\n",
    "\n",
    "configs = []  # List of NNLayerConfig objects\n",
    "\n",
    "# Configuration for the experiment. For now do nothing with stride and padding.\n",
    "s1 = [1, 2, 3]\n",
    "s2 = [2, 1, 1]\n",
    "dim1 = 64\n",
    "dim2 = 1\n",
    "for (f1s, f2s) in zip(s1, s2):\n",
    "    configs.append(NNLayerConfig(   \n",
    "                                    loss = 0,\n",
    "                                    num_params = 0,\n",
    "                                    filter1_size = f1s, \n",
    "                                    filter1_stride = 1,\n",
    "                                    filter1_padding =  0,\n",
    "                                    filter2_size = f2s,\n",
    "                                    filter2_stride = 1,\n",
    "                                    filter2_padding = 0,\n",
    "                                    dim_1 = dim1,\n",
    "                                    dim_2 = dim2\n",
    "                                    ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define model\n",
    "class ExpCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutions are set separately\n",
    "       \n",
    "        # Dense is default\n",
    "        \n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10)\n",
    "        )\n",
    "\n",
    "    def set_convolution(self, conv : nn.Sequential):\n",
    "        self.convolutions = conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "# Loop through some kernel sizes\n",
    "for ksize in range(2,4):\n",
    "    conv = nn.Conv2d(\n",
    "        in_channels=1, \n",
    "        out_channels=32,\n",
    "        kernel_size=ksize,\n",
    "        padding=(1,1),\n",
    "        stride=2)\n",
    "    \n",
    "    model = ExpCNN().to(device)\n",
    "    model.set_convolution(nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=ksize, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            # The original:\n",
    "            # nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2),\n",
    "            # nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2),\n",
    "            # nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "\n",
    "        ))\n",
    "\n",
    "    # Now train\n",
    "    model = train_model.trainloop(\n",
    "        epochs=2, # was 10\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        learning_rate=1e-3,\n",
    "        loss_fn=loss_fn,\n",
    "        metrics=[accuracy],\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        log_dir=\"../models/test/\",\n",
    "        train_steps=len(train_dataloader),\n",
    "        eval_steps=len(test_dataloader),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkout results using tensorboard: \n",
    "- run `tensorboard --logdir models` in the terminal\n",
    "- tensorboard will launch at `localhost:6006` and vscode will notify you that the port is forwarded\n",
    "- you can either press the `launch` button in VScode or open your local browser at `localhost:6006`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
