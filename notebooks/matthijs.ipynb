{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoI ML CNN Experiment\n",
    "\n",
    "- Train op fashion mnist\n",
    "- Laat experimenten zien: kies 2 - 3 params, kies een range en voer tests uit. Doel is 93% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import make_dataset\n",
    "from src.models import imagemodels\n",
    "from src.models import train_model\n",
    "import gin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedConfigFileIncludesAndImports(filename='cnn.gin', imports=[], includes=[])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load config for this notebook\n",
    "gin.parse_config_file(\"cnn.gin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MNIST data\n",
    "train_dataloader, test_dataloader = make_dataset.get_MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set some other parameters\n",
    "import torch.optim as optim\n",
    "from src.models import metrics\n",
    "optimizer = optim.Adam\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "accuracy = metrics.Accuracy()\n",
    "from src.models import train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voer een experiment uit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuratie voor het experiment\n",
    "\n",
    "Sla de gewenste structuur voor de lagen op in een lijst configuraties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class NNLayerConfig:\n",
    "    \"\"\"Class for storing config and results for a layer.\"\"\"\n",
    "    loss: float\n",
    "    num_params: int\n",
    "    filter1_size: int\n",
    "    filter1_stride: int\n",
    "    filter1_padding: int\n",
    "    filter2_size: int\n",
    "    filter2_stride: int\n",
    "    filter2_padding: int\n",
    "    dim_1: int\n",
    "    dim_2: int\n",
    "\n",
    "    # TODO calculate input and output dims\n",
    "    def calc_dim_1():\n",
    "        return 0\n",
    "    def calc_dim_2():\n",
    "        return 0\n",
    "\n",
    "configs = []  # List of NNLayerConfig objects\n",
    "\n",
    "# Configuration for the experiment. For now do nothing with stride and padding.\n",
    "s1 = [1, 2, 3]\n",
    "s2 = [2, 1, 1]\n",
    "dim1 = 64\n",
    "dim2 = 1\n",
    "for (f1s, f2s) in zip(s1, s2):\n",
    "    configs.append(NNLayerConfig(   \n",
    "                                    loss = 0,\n",
    "                                    num_params = 0,\n",
    "                                    filter1_size = f1s, \n",
    "                                    filter1_stride = 1,\n",
    "                                    filter1_padding =  0,\n",
    "                                    filter2_size = f2s,\n",
    "                                    filter2_stride = 1,\n",
    "                                    filter2_padding = 0,\n",
    "                                    dim_1 = dim1,\n",
    "                                    dim_2 = dim2\n",
    "                                    ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maak een klasse die met een configuratie als input een NN maakt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32//3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define model\n",
    "class ConfigurableNN (nn.Module):\n",
    "\n",
    "    def __init__(self, config:NNLayerConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.num_filters_l1 = 32 # TODO from config\n",
    "        self.max_pool_ksize = 2 # TODO from config\n",
    "\n",
    "\n",
    "\n",
    "        # Convolutions are set separately\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(  1, # First one is always 1\n",
    "                        self.num_filters_l1, \n",
    "                        kernel_size = config.filter1_size,\n",
    "                        stride = config.filter1_stride,\n",
    "                        padding = config.filter1_padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=self.max_pool_ksize),\n",
    "            nn.Conv2d(  self.num_filters_l1,\n",
    "                        self.num_filters_l1 * 2,\n",
    "                        kernel_size = config.filter2_size,\n",
    "                        stride = config.filter2_stride,\n",
    "                        padding = config.filter2_padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=self.max_pool_ksize)\n",
    "\n",
    "            # Werkend voorbeeld:\n",
    "            # nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2),\n",
    "            # nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2),\n",
    "            # nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "\n",
    "        )\n",
    "        \n",
    "        # Dense is default for now.\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32, 64),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(64, 32),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(32, 10)\n",
    "        )\n",
    "\n",
    "    # Forward is default for now.\n",
    "    def forward(self, x):\n",
    "        x = self.convolutions(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop door de configuraties heen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape is:\n",
      "torch.Size([32, 1, 28, 28])\n",
      "================\n",
      "STARTING NEW MODEL\n",
      "================\n",
      "ConfigurableNN(\n",
      "  (convolutions): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (dense): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=32, out_features=64, bias=True)\n",
      "  )\n",
      ")\n",
      "-----------------\n",
      "Convolution:\n",
      "Conv2d(1, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "torch.Size([32, 32, 28, 28])\n",
      "-----------------\n",
      "Convolution:\n",
      "ReLU()\n",
      "torch.Size([32, 32, 28, 28])\n",
      "-----------------\n",
      "Convolution:\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "torch.Size([32, 32, 14, 14])\n",
      "-----------------\n",
      "Convolution:\n",
      "Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "torch.Size([32, 64, 13, 13])\n",
      "-----------------\n",
      "Convolution:\n",
      "ReLU()\n",
      "torch.Size([32, 64, 13, 13])\n",
      "-----------------\n",
      "Convolution:\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "torch.Size([32, 64, 6, 6])\n",
      "-----------------\n",
      "Examining dense:\n",
      "-----------------\n",
      "-----------------\n",
      "Dense:\n",
      "Flatten(start_dim=1, end_dim=-1)\n",
      "torch.Size([32, 2304])\n",
      "-----------------\n",
      "Dense:\n",
      "Linear(in_features=32, out_features=64, bias=True)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x2304 and 32x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDense:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m     \u001b[39mprint\u001b[39m(dense)\n\u001b[0;32m---> 32\u001b[0m     out \u001b[39m=\u001b[39m dense(out)\n\u001b[1;32m     33\u001b[0m     \u001b[39mprint\u001b[39m(out\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     34\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x2304 and 32x64)"
     ]
    }
   ],
   "source": [
    "num_epochs = 2 # During development keep very low. 10 is for real tests\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# For to be debugging:\n",
    "x, y = next(iter(train_dataloader))\n",
    "x.shape, y.shape\n",
    "\n",
    "print(\"input shape is:\")\n",
    "print(x.shape)\n",
    "\n",
    "for config in configs:\n",
    "    model = ConfigurableNN(config).to(device)\n",
    "    print(\"================\")\n",
    "    print(\"STARTING NEW MODEL\")\n",
    "    print(\"================\")\n",
    "    print(model)\n",
    "\n",
    "    out = x\n",
    "    for conv in model.convolutions:\n",
    "        print(\"-----------------\")\n",
    "        print(\"Convolution:\")\n",
    "        print(conv)\n",
    "        out = conv(out)\n",
    "        print(out.shape)\n",
    "    print(\"-----------------\")\n",
    "    print(\"Examining dense:\")\n",
    "    print(\"-----------------\")\n",
    "    for dense in model.dense:\n",
    "        print(\"-----------------\")\n",
    "        print(\"Dense:\")\n",
    "        print(dense)\n",
    "        out = dense(out)\n",
    "        print(out.shape)\n",
    "    break\n",
    "    model = train_model.trainloop(\n",
    "        epochs=num_epochs,\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        learning_rate=learning_rate,\n",
    "        loss_fn=loss_fn,\n",
    "        metrics=[accuracy],\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        log_dir=\"../models/test/\",\n",
    "        train_steps=len(train_dataloader),\n",
    "        eval_steps=len(test_dataloader),\n",
    "    )\n",
    "    break # During development\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through some kernel sizes\n",
    "for ksize in range(2,4):\n",
    "\n",
    "    \n",
    "    model = ExpCNN().to(device)\n",
    "    model.set_convolution(nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=ksize, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "\n",
    "        ))\n",
    "\n",
    "    # Now train\n",
    "    model = train_model.trainloop(\n",
    "        epochs=2, # was 10\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        learning_rate=1e-3,\n",
    "        loss_fn=loss_fn,\n",
    "        metrics=[accuracy],\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        log_dir=\"../models/test/\",\n",
    "        train_steps=len(train_dataloader),\n",
    "        eval_steps=len(test_dataloader),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkout results using tensorboard: \n",
    "- run `tensorboard --logdir models` in the terminal\n",
    "- tensorboard will launch at `localhost:6006` and vscode will notify you that the port is forwarded\n",
    "- you can either press the `launch` button in VScode or open your local browser at `localhost:6006`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
